{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Initial Parsing\n",
    "\n",
    "Before doing more fine-grained parsing on individual resume sections (Education, Experience, etc.), we need to parse the sections out\n",
    "\n",
    "Couple of options:\n",
    "\n",
    "1. Regex-based\n",
    "2. Text-only LLM\n",
    "3. Vision LLM (for PDFs that are not formatted with text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "from pydantic import BaseModel, RootModel, Field\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "from pytesseract import pytesseract\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from resume_scanner.utils.with_structured_output import with_structured_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Key Information With Regex\n",
    "\n",
    "1. Phone number\n",
    "2. Email\n",
    "3. LinkedIn\n",
    "4. GitHub\n",
    "5. Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phone number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_phone_number(text: str) -> str:\n",
    "    phone_pattern = re.compile(r\"\"\"\n",
    "        (?:\\+(?P<country_code>1)+\\s)?   # Match country code (if exists)\n",
    "        (?:\\()?\n",
    "        (?P<area_code>\\d{3})            # Match area code (first 3 digits)\n",
    "        (?:[.-]|\\)\\s?)\n",
    "        (?P<prefix>\\d{3})               # Match prefix (second 3 digits)\n",
    "        [.-]\n",
    "        (?P<line_number>\\d{4})          # Match line number (last 4 digits)\n",
    "    \"\"\", re.VERBOSE)\n",
    "    match = re.search(phone_pattern, text)\n",
    "    if match:\n",
    "        return f\"{match.group(\"area_code\")}-{match.group(\"prefix\")}-{match.group(\"line_number\")}\"\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_number = \"(832) 416-3570\"\n",
    "\n",
    "parse_phone_number(phone_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_email(text: str) -> str:\n",
    "    email_pattern = re.compile(r\"\"\"\n",
    "        \\b\n",
    "        [A-Za-z0-9._%+-]+   # Local part\n",
    "        @\n",
    "        [A-Za-z0-9.-]+      # Domain \n",
    "        \\.[A-Za-z]{2,}\n",
    "        \\b\n",
    "    \"\"\", re.VERBOSE)\n",
    "    match = re.search(email_pattern, text)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = \"Some leading text: kevzhang2022@tamu.edu and trailing text\"\n",
    "\n",
    "parse_email(email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_linkedin(text: str) -> str:\n",
    "    linkedin_pattern = r\"(?:(?:https://)?(?:www.)?linkedin.com/in/(?P<profile_id>[A-Za-z0-9-]{5,30})/?\\b)\"\n",
    "    match = re.search(linkedin_pattern, text)\n",
    "    if match:\n",
    "        return f\"https://linkedin.com/in/{match.group(\"profile_id\")}\"\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin = \"LinkedIn: linkedin.com/in/kevinkz some trailing text\"\n",
    "\n",
    "parse_linkedin(linkedin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_github(text: str) -> str:\n",
    "    github_pattern = r\"(?:(?:https://)?(?:www.)?github.com/(?P<username>[A-Za-z0-9-]{1,39})/?\\b)\"\n",
    "    match = re.search(github_pattern, text)\n",
    "    if match:\n",
    "        return f\"https://github.com/{match.group(\"username\")}\"\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github = \"GitHub: github.com/n1v3x2 some trailing text\"\n",
    "\n",
    "parse_github(github)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_location(text: str) -> str:\n",
    "    location_pattern = r\"(?P<city>\\b[A-Za-z0-9]+(?:(?:[ .'-]|. )[A-Za-z0-9]+)*),\\s?(?P<state>[A-Z]{2})\"\n",
    "    match = re.search(location_pattern, text)\n",
    "    if match:\n",
    "        return f\"{match.group(\"city\")}, {match.group(\"state\")}\"\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"College Station, TX\"\n",
    "\n",
    "parse_location(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tying it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_text = extract_pdf_text(\"../input/resumes/Kareem_resume.pdf\")\n",
    "parsed_info = {\n",
    "    \"Phone\": parse_phone_number(resume_text),\n",
    "    \"Email\": parse_email(resume_text),\n",
    "    \"LinkedIn\": parse_linkedin(resume_text),\n",
    "    \"GitHub\": parse_github(resume_text),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Purely Regex-Based Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "heading_map = {\n",
    "    # Experience\n",
    "    r\"(Work|Relevant|Professional)?\\s*(Experience|History)\": \"Experience\",\n",
    "    r\"(Employment|Career)\\s*(History|Experience)\": \"Experience\",\n",
    "    r\"(Internship|Internships|Intern Experiences?)\": \"Experience\",\n",
    "    r\"(Freelance|Contract)\\s*(Work|Experience)\": \"Experience\",\n",
    "    r\"Work\": \"Experience\",\n",
    "\n",
    "    # Education\n",
    "    r\"(Education|Educational Background|Academic History|Academic Background)\": \"Education\",\n",
    "    r\"(Certifications|Courses|Licenses|Trainings|Accreditations)\": \"Certifications\",\n",
    "    r\"(Professional Development|Learning)\": \"Certifications\",\n",
    "\n",
    "    # Skills\n",
    "    r\"(Skills|Technical Skills|Key Competencies|Core Competencies|Abilities)\": \"Skills\",\n",
    "    r\"(Technical Proficiencies|Technical Expertise|Expertise|Proficiencies)\": \"Skills\",\n",
    "    r\"(Languages|Programming Languages)\": \"Skills\",\n",
    "    \n",
    "    # Projects\n",
    "    r\"(Projects|Key Projects|Personal Projects|Side Projects)\": \"Projects\",\n",
    "    r\"(Freelance Projects|Independent Projects|Portfolio)\": \"Projects\",\n",
    "\n",
    "    # Achievements and Awards\n",
    "    r\"(Achievements?|Awards?|Honors?|Accolades?|Recognitions?)\": \"Achievements\",\n",
    "    r\"(Accomplishments|Milestones)\": \"Achievements\",\n",
    "\n",
    "    # Volunteer Work\n",
    "    r\"(Volunteer|Volunteering|Community( Service)?|Volunteer Experience)\": \"Volunteer Work\",\n",
    "    r\"(Social Work|Non-Profit Work)\": \"Volunteer Work\",\n",
    "\n",
    "    # Leadership\n",
    "    r\"(Leadership|Leadership Experience|Leadership Roles|Positions of Responsibility)\": \"Leadership\",\n",
    "    r\"(Managerial Experience|Team Leadership|Organizational Roles)\": \"Leadership\",\n",
    "\n",
    "    # Publications and Research\n",
    "    r\"(Publications?|Research|Academic Papers|Articles|Journals?)\": \"Publications\",\n",
    "    r\"(Research Projects|Thesis|Dissertation)\": \"Research\",\n",
    "\n",
    "    # Interests and Hobbies\n",
    "    r\"(Interests?|Hobbies?|(Extracurricular|Collegiate) Activities)\": \"Interests\",\n",
    "    r\"(Passions?|Leisure Activities)\": \"Interests\",\n",
    "\n",
    "    # Objective or Summary\n",
    "    r\"(Objective|Career Objective|Professional Objective)\": \"Summary\",\n",
    "    r\"(Summary|Professional (Highlights|Profile|Summary)|Career Summary)\": \"Summary\",\n",
    "\n",
    "    # References\n",
    "    r\"(References?|Professional References|Referees?)\": \"References\",\n",
    "}\n",
    "\n",
    "def normalize_heading(heading):\n",
    "    for pattern, normalized_heading in heading_map.items():\n",
    "        if re.search(pattern, heading, re.IGNORECASE):\n",
    "            return normalized_heading\n",
    "    return \"Miscellaneous\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sections_by_heading(resume_text: str) -> dict[str, str]:\n",
    "    heading_pattern = r\"\"\"\n",
    "        ^(                                  \n",
    "            [A-Z][a-z]+(?:\\ [A-Z][a-z]+)?(?:[\\s]*\\n)    # Matches Captialized headings\n",
    "            |\n",
    "            [A-Z]{3,}(?:\\ [A-Z]{2,})*(?::?[\\s]*\\n)      # Matches ALL CAPS headings \n",
    "        )\n",
    "    \"\"\"\n",
    "    heading_regex = re.compile(heading_pattern, re.VERBOSE | re.MULTILINE)\n",
    "    matches = list(re.finditer(heading_regex, resume_text))\n",
    "    \n",
    "    sections = defaultdict(list)\n",
    "    for i, match in enumerate(matches):\n",
    "        # The section starts at the end of the heading\n",
    "        start = match.end()\n",
    "        # The section ends at the start of the next heading or the end of the resume\n",
    "        end = matches[i + 1].start() if i + 1 < len(matches) else len(resume_text)\n",
    "        \n",
    "        heading = match.group(1).strip()\n",
    "        normalized_heading = normalize_heading(heading)\n",
    "        \n",
    "        if normalized_heading == \"Miscellaneous\":\n",
    "            sections[normalized_heading].append(resume_text[start:end].strip())\n",
    "        else :\n",
    "            sections[normalized_heading] = resume_text[start:end].strip()\n",
    "    \n",
    "    return dict(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_text = extract_pdf_text(\"../sample-data/Ben_Resume.pdf\")\n",
    "resume_sections = extract_sections_by_heading(resume_text)\n",
    "pprint(resume_sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regex-based parsing is too inflexible for handling a wide variety of resume formats... maybe an LLM-based solution would work better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: LLM with Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resume(BaseModel):\n",
    "    experience: str = Field(..., alias=\"Experience\")\n",
    "    education: str  = Field(..., alias=\"Education\")\n",
    "    skills: str     = Field(..., alias=\"Skills\")\n",
    "    projects: str   = Field(..., alias=\"Projects\")\n",
    "    leadership: str = Field(..., alias=\"Leadership\")\n",
    "    research: str   = Field(..., alias=\"Research\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_EXTRACTION_PROMPT = \"\"\"\n",
    "You are an expert at parsing resume information. Given resume text, your job is to parse individual sections based on resume heading. Follow this format:\n",
    "    {{\n",
    "        \"Experience\": \"<Experience>\",\n",
    "        \"Education\": \"<Education>\",\n",
    "        \"Skills\": \"<Skills>\",\n",
    "        \"Projects\": \"<Projects>\",\n",
    "        \"Leadership\": \"<Leadership Experience>\",\n",
    "        \"Research\": \"<Research Experience>\"\n",
    "    }}\n",
    "    \n",
    "Your job is very simple: simply copy everything under each resume section into the output format; do not worry about formatting. \n",
    "\n",
    "If a resume does not contain one of the sections, output an empty string for that section. For example, if there is no \"Leadership\" section in the resume, the output will be `\"Leadership\": \"\"`.\n",
    "\n",
    "In the experience section, **ensure that you include company names**, which are usually listed beside or under position names.\n",
    "\n",
    "**The parsed information must be explicitly contained in the resume.**\n",
    "\n",
    "**Do not exclude any information from the resume.**\n",
    "\n",
    "Resume:\n",
    "{resume_text}\n",
    "\n",
    "Output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_text = extract_pdf_text(\"../input/resumes/Kevin_resume.pdf\")\n",
    "parsed_resume = with_structured_output(\n",
    "    prompt=INITIAL_EXTRACTION_PROMPT.format(resume_text=resume_text),\n",
    "    schema=Resume,\n",
    "    model=\"llama3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add regex-parsed sections to output, but don't include it in the parsed resume output for privacy reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_info = {\n",
    "    \"Phone\": parse_phone_number(resume_text),\n",
    "    \"Email\": parse_email(resume_text),\n",
    "    \"LinkedIn\": parse_linkedin(resume_text),\n",
    "    \"GitHub\": parse_github(resume_text),\n",
    "}\n",
    "\n",
    "with open(\"../output/parsed_personal_info.json\", \"w\") as file:\n",
    "    json.dump(parsed_info, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../output/parsed_resume.json\", \"w\") as file:\n",
    "    json.dump(parsed_resume, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "HF_API_KEY = os.getenv(\"HF_API_KEY\")\n",
    "client = InferenceClient(token=HF_API_KEY)\n",
    "\n",
    "response = client.text_generation(\n",
    "    model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    prompt=\"Answer concisely: What is 10 x 10?\",\n",
    "    max_new_tokens=50)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.text_generation(\n",
    "    model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    prompt=INITIAL_EXTRACTION_PROMPT.format(resume_text=resume_text),\n",
    "    grammar={\n",
    "        \"type\": \"json\",\n",
    "        \"value\": Resume.model_json_schema()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need HF Pro subscription to access some Llama models; I think Ollama might be my best option after all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 3: Vision Model Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_pdf_text(\"../sample_data/Kevin_resume_img.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the PDF to an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = convert_from_path(\"../sample_data/Ben_resume.pdf\", dpi=300)\n",
    "\n",
    "for i, image in enumerate(images):\n",
    "    image.save(f\"output/Ben_resume.jpg\", \"JPEG\")\n",
    "    print(f\"Saved page {i + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the vision model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_EXTRACTION_PROMPT = \"\"\"\n",
    "You are an expert at parsing resume information from an image. Given an image of a resume, your job is to parse individual sections based on resume heading. Follow this format:\n",
    "    {{\n",
    "        \"Experience\": \"<Experience>\",\n",
    "        \"Education\": \"<Education>\",\n",
    "        \"Skills\": \"<Skills>\",\n",
    "        \"Projects\": \"<Projects>\",\n",
    "        \"Leadership\": \"<Leadership Experience>\",\n",
    "        \"Research\": \"<Research Experience>\"\n",
    "    }}\n",
    "    \n",
    "Your job is very simple: simply copy everything under each resume section into the output format; do not worry about formatting. \n",
    "\n",
    "If a resume does not contain one of the sections, output an empty string for that section. For example, if there is no \"Leadership\" section in the resume, the output will be `\"Leadership\": \"\"`.\n",
    "\n",
    "In the experience section, **ensure that you include company names**, which are usually listed beside or under position names.\n",
    "\n",
    "**The parsed information must be explicitly contained in the resume.**\n",
    "\n",
    "**Do not exclude any information from the resume.**\n",
    "\n",
    "Output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "\n",
    "response = chat(\n",
    "    model=\"llama3.2-vision\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": IMAGE_EXTRACTION_PROMPT,\n",
    "            \"images\": [\"output/Ben_resume.jpg\"]\n",
    "        }\n",
    "    ],\n",
    "    format=Resume.model_json_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_resume = json.loads(response.message.content)\n",
    "pprint(parsed_resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bad with VLMs:\n",
    "1. Most state-of-the-art VLMs cannot process very large images (e.g., Llama3.2-vision can only process images up to 1120x1120)\n",
    "2. llama3.2-vision runs pretty slow on my computer, probably because it requires 11B parameters vs only 8B from llama3.1\n",
    "3. llama3.2-vision isn't very good at parsing a lot of textual information from resumes; it's missing a lot of information from the \"Experience\" section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Option 4: OCR -> LLM parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_images = convert_from_path(\"../sample_data/Kevin_resume.pdf\", dpi=300)\n",
    "pdf_images[0].save(\"output/Kevin_resume.png\", \"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_pdf_text = pytesseract.image_to_string(pdf_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(extracted_pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resume(BaseModel):\n",
    "    experience: str = Field(..., alias=\"Experience\")\n",
    "    education: str  = Field(..., alias=\"Education\")\n",
    "    skills: str     = Field(..., alias=\"Skills\")\n",
    "    projects: str   = Field(..., alias=\"Projects\")\n",
    "    leadership: str = Field(..., alias=\"Leadership\")\n",
    "    research: str   = Field(..., alias=\"Research\")\n",
    "    \n",
    "INITIAL_EXTRACTION_PROMPT = \"\"\"\n",
    "You are an expert at parsing resume information. Given resume text, your job is to parse individual sections based on resume heading. Follow this format:\n",
    "    {{\n",
    "        \"Experience\": \"<Experience>\",\n",
    "        \"Education\": \"<Education>\",\n",
    "        \"Skills\": \"<Skills>\",\n",
    "        \"Projects\": \"<Projects>\",\n",
    "        \"Leadership\": \"<Leadership Experience>\",\n",
    "        \"Research\": \"<Research Experience>\"\n",
    "    }}\n",
    "    \n",
    "Your job is very simple: simply copy everything under each resume section into the output format; do not worry about formatting. \n",
    "\n",
    "If a resume does not contain one of the sections, output an empty string for that section. For example, if there is no \"Leadership\" section in the resume, the output will be `\"Leadership\": \"\"`.\n",
    "\n",
    "In the experience section, **ensure that you include company names**, which are usually listed beside or under position names.\n",
    "\n",
    "**The parsed information must be explicitly contained in the resume.**\n",
    "\n",
    "**Do not exclude any information from the resume.**\n",
    "\n",
    "Resume:\n",
    "{resume_text}\n",
    "\n",
    "Output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_resume = with_structured_output(\n",
    "    prompt=INITIAL_EXTRACTION_PROMPT.format(resume_text=extracted_pdf_text),\n",
    "    schema=Resume,\n",
    "    model=\"llama3.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(parsed_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
