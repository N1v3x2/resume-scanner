{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pdfplumber\n",
    "import ollama\n",
    "from pprint import pprint\n",
    "from pydantic import BaseModel, RootModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../sample-data/job-desc.txt\", \"r\") as file:\n",
    "    job_desc = file.read()\n",
    "    \n",
    "with open(\"../sample-data/resumes.json\", \"r\") as file:\n",
    "    resumes = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_text(pdf_path: str) -> str:\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "my_resume = extract_pdf_text(\"../sample-data/sample.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### TF-IDF for keyword extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pprint import pprint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abc', 'abilities', 'adhering', 'agile', 'apis', 'application',\n",
       "       'applications', 'architecture', 'attention', 'bachelor', 'best',\n",
       "       'boot', 'built', 'clean', 'closely', 'code', 'collaborate',\n",
       "       'collaboration', 'com', 'commerce', 'communication', 'complex',\n",
       "       'computer', 'cross', 'databases', 'debug', 'degree', 'deliver',\n",
       "       'deploy', 'description', 'design', 'designers', 'develop',\n",
       "       'developing', 'development', 'django', 'docker', 'doe', 'downtime',\n",
       "       'dynamic', 'education', 'efficient', 'engineer', 'engineering',\n",
       "       'environment', 'equivalent', 'example', 'excellent', 'experience',\n",
       "       'experienced', 'expertise', 'field', 'frameworks', 'functional',\n",
       "       'gather', 'git', 'growth', 'high', 'innovation', 'java',\n",
       "       'javascript', 'job', 'john', 'johndoe', 'join', 'june',\n",
       "       'knowledge', 'kubernetes', 'languages', 'led', 'linkedin',\n",
       "       'maintain', 'maintainable', 'maintained', 'managers', 'members',\n",
       "       'methodologies', 'microservices', 'migration', 'modern', 'mongodb',\n",
       "       'monolithic', 'optimize', 'passion', 'passionate', 'performance',\n",
       "       'platforms', 'postgresql', 'practices', 'present', 'problem',\n",
       "       'problems', 'product', 'proficiency', 'programming', 'python',\n",
       "       'qualifications', 'quality', 'react', 'reducing', 'refine',\n",
       "       'related', 'requirements', 'responsibilities', 'role',\n",
       "       'scalability', 'scalable', 'science', 'seeking', 'services',\n",
       "       'skills', 'software', 'solutions', 'solve', 'solving', 'spring',\n",
       "       'strong', 'summary', 'support', 'talented', 'team', 'teams',\n",
       "       'teamwork', 'tech', 'test', 'title', 'tools', 'traffic',\n",
       "       'troubleshoot', 'university', 'using', 'values', 'web', 'work',\n",
       "       'write', 'xyz'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [resumes[0], job_desc]\n",
    "\n",
    "# Remove numbers before extracting keywords\n",
    "corpus = [re.sub(r\"\\d+\", \"\", text) for text in corpus]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "tfidf_scores = tfidf_matrix.toarray()\n",
    "\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Resume Keywords:\n",
      "[('software', 0.2405245183143361),\n",
      " ('engineer', 0.2405245183143361),\n",
      " ('javascript', 0.22536587875688172),\n",
      " ('com', 0.22536587875688172),\n",
      " ('doe', 0.22536587875688172),\n",
      " ('john', 0.22536587875688172),\n",
      " ('python', 0.1603496788762241),\n",
      " ('scalable', 0.1603496788762241),\n",
      " ('migration', 0.11268293937844086),\n",
      " ('microservices', 0.11268293937844086),\n",
      " ('maintained', 0.11268293937844086),\n",
      " ('mongodb', 0.11268293937844086),\n",
      " ('linkedin', 0.11268293937844086),\n",
      " ('monolithic', 0.11268293937844086),\n",
      " ('led', 0.11268293937844086),\n",
      " ('knowledge', 0.11268293937844086),\n",
      " ('passion', 0.11268293937844086),\n",
      " ('june', 0.11268293937844086),\n",
      " ('platforms', 0.11268293937844086),\n",
      " ('postgresql', 0.11268293937844086),\n",
      " ('johndoe', 0.11268293937844086),\n",
      " ('xyz', 0.11268293937844086),\n",
      " ('expertise', 0.11268293937844086),\n",
      " ('git', 0.11268293937844086),\n",
      " ('experienced', 0.11268293937844086),\n",
      " ('example', 0.11268293937844086),\n",
      " ('education', 0.11268293937844086),\n",
      " ('downtime', 0.11268293937844086),\n",
      " ('docker', 0.11268293937844086),\n",
      " ('django', 0.11268293937844086),\n",
      " ('developing', 0.11268293937844086),\n",
      " ('databases', 0.11268293937844086),\n",
      " ('commerce', 0.11268293937844086),\n",
      " ('built', 0.11268293937844086),\n",
      " ('boot', 0.11268293937844086),\n",
      " ('architecture', 0.11268293937844086),\n",
      " ('application', 0.11268293937844086),\n",
      " ('apis', 0.11268293937844086),\n",
      " ('present', 0.11268293937844086),\n",
      " ('kubernetes', 0.11268293937844086),\n",
      " ('abc', 0.11268293937844086),\n",
      " ('tech', 0.11268293937844086),\n",
      " ('support', 0.11268293937844086),\n",
      " ('summary', 0.11268293937844086),\n",
      " ('web', 0.11268293937844086),\n",
      " ('react', 0.11268293937844086),\n",
      " ('reducing', 0.11268293937844086),\n",
      " ('traffic', 0.11268293937844086),\n",
      " ('spring', 0.11268293937844086),\n",
      " ('university', 0.11268293937844086),\n",
      " ('solving', 0.08017483943811204),\n",
      " ('complex', 0.08017483943811204),\n",
      " ('languages', 0.08017483943811204),\n",
      " ('skills', 0.08017483943811204),\n",
      " ('tools', 0.08017483943811204),\n",
      " ('frameworks', 0.08017483943811204),\n",
      " ('java', 0.08017483943811204),\n",
      " ('high', 0.08017483943811204),\n",
      " ('strong', 0.08017483943811204),\n",
      " ('experience', 0.08017483943811204),\n",
      " ('programming', 0.08017483943811204),\n",
      " ('science', 0.08017483943811204),\n",
      " ('computer', 0.08017483943811204),\n",
      " ('problems', 0.08017483943811204),\n",
      " ('applications', 0.08017483943811204),\n",
      " ('troubleshoot', 0.0),\n",
      " ('attention', 0.0),\n",
      " ('teamwork', 0.0),\n",
      " ('abilities', 0.0),\n",
      " ('test', 0.0),\n",
      " ('development', 0.0),\n",
      " ('title', 0.0),\n",
      " ('adhering', 0.0),\n",
      " ('agile', 0.0),\n",
      " ('work', 0.0),\n",
      " ('develop', 0.0),\n",
      " ('values', 0.0),\n",
      " ('designers', 0.0),\n",
      " ('design', 0.0),\n",
      " ('description', 0.0),\n",
      " ('communication', 0.0),\n",
      " ('bachelor', 0.0),\n",
      " ('deploy', 0.0),\n",
      " ('best', 0.0),\n",
      " ('using', 0.0),\n",
      " ('deliver', 0.0),\n",
      " ('degree', 0.0),\n",
      " ('debug', 0.0),\n",
      " ('clean', 0.0),\n",
      " ('closely', 0.0),\n",
      " ('cross', 0.0),\n",
      " ('dynamic', 0.0),\n",
      " ('code', 0.0),\n",
      " ('collaborate', 0.0),\n",
      " ('collaboration', 0.0),\n",
      " ('teams', 0.0),\n",
      " ('qualifications', 0.0),\n",
      " ('team', 0.0),\n",
      " ('optimize', 0.0),\n",
      " ('members', 0.0),\n",
      " ('methodologies', 0.0),\n",
      " ('role', 0.0),\n",
      " ('responsibilities', 0.0),\n",
      " ('modern', 0.0),\n",
      " ('requirements', 0.0),\n",
      " ('related', 0.0),\n",
      " ('refine', 0.0),\n",
      " ('scalability', 0.0),\n",
      " ('passionate', 0.0),\n",
      " ('performance', 0.0),\n",
      " ('practices', 0.0),\n",
      " ('quality', 0.0),\n",
      " ('problem', 0.0),\n",
      " ('product', 0.0),\n",
      " ('proficiency', 0.0),\n",
      " ('managers', 0.0),\n",
      " ('maintainable', 0.0),\n",
      " ('efficient', 0.0),\n",
      " ('growth', 0.0),\n",
      " ('talented', 0.0),\n",
      " ('engineering', 0.0),\n",
      " ('environment', 0.0),\n",
      " ('equivalent', 0.0),\n",
      " ('field', 0.0),\n",
      " ('functional', 0.0),\n",
      " ('gather', 0.0),\n",
      " ('innovation', 0.0),\n",
      " ('maintain', 0.0),\n",
      " ('job', 0.0),\n",
      " ('solve', 0.0),\n",
      " ('solutions', 0.0),\n",
      " ('join', 0.0),\n",
      " ('services', 0.0),\n",
      " ('write', 0.0),\n",
      " ('seeking', 0.0),\n",
      " ('excellent', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "resume_keywords = [\n",
    "    (feature_names[i], tfidf_scores[0][i])\n",
    "    for i in tfidf_scores[0].argsort()[::-1]\n",
    "]\n",
    "print(\"Top Resume Keywords:\")\n",
    "pprint(resume_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF isn't ideal for matching keywords between a resume and a job description, since TF-IDF assigns higher scores for words that are *unique*. If a word appears in both the resume and job description, its *uniqueness* score is decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NLP libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(resumes[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/resume/lib/python3.12/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/resume/lib/python3.12/site-packages/spacy/util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(resumes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "John Doe\n",
       "Software Engineer\n",
       "john.doe@example.com | (123) 456-7890 | linkedin.com/in/johndoe\n",
       "\n",
       "Summary:\n",
       "Experienced software engineer with expertise in developing scalable web applications, strong knowledge of Python and JavaScript, and a passion for solving complex problems.\n",
       "\n",
       "Skills:\n",
       "- Programming Languages: Python, JavaScript, Java\n",
       "- Frameworks: Django, React, Spring Boot\n",
       "- Tools: Git, Docker, Kubernetes\n",
       "- Databases: PostgreSQL, MongoDB\n",
       "\n",
       "Experience:\n",
       "Software Engineer | ABC Tech | June 2020 - Present\n",
       "- Built and maintained scalable APIs to support high-traffic e-commerce platforms.\n",
       "- Led migration of a monolithic application to a microservices architecture, reducing downtime by 30%.\n",
       "\n",
       "Education:\n",
       "B.S. in Computer Science | University of XYZ | May 2020"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['software',\n",
       " 'engineer',\n",
       " 'expertise',\n",
       " 'web',\n",
       " 'applications',\n",
       " 'knowledge',\n",
       " 'passion',\n",
       " 'problems',\n",
       " 'Skills',\n",
       " 'Languages',\n",
       " 'MongoDB',\n",
       " 'Experience',\n",
       " 'APIs',\n",
       " 'traffic',\n",
       " 'commerce',\n",
       " 'platforms',\n",
       " 'migration',\n",
       " 'application',\n",
       " 'microservices',\n",
       " 'architecture',\n",
       " 'downtime']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = [re.sub(f\"[^a-zA-Z]\", \"\", token.text) for token in doc if token.pos_ == \"NOUN\"]\n",
    "keywords = [keyword for keyword in keywords if keyword and len(keyword) > 1]\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('John Doe\\n', 'PERSON'),\n",
       " ('Software Engineer', 'ORG'),\n",
       " ('123', 'CARDINAL'),\n",
       " ('456', 'CARDINAL'),\n",
       " ('JavaScript', 'PRODUCT'),\n",
       " ('JavaScript', 'PRODUCT'),\n",
       " ('Java\\n- Frameworks:', 'PERSON'),\n",
       " ('Git', 'GPE'),\n",
       " ('Docker', 'GPE'),\n",
       " ('Kubernetes', 'ORG'),\n",
       " ('Software Engineer', 'ORG'),\n",
       " ('ABC Tech', 'ORG'),\n",
       " ('June 2020 - Present', 'DATE'),\n",
       " ('30%', 'PERCENT'),\n",
       " ('B.S.', 'GPE'),\n",
       " ('Computer Science', 'ORG'),\n",
       " ('University of XYZ', 'ORG'),\n",
       " ('May 2020', 'DATE')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NER models are good for identifying general-purpose entities, but struggle to identify skills out of the box. Perhaps I need to fine-tune a model? Or use a transformer-based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The sky appears blue because of a phenomenon called scattering, which occurs when sunlight interacts with the tiny molecules of gases in the Earth's atmosphere. Here's a simplified explanation:\\n\\n1. Sunlight enters the Earth's atmosphere and is made up of a spectrum of colors, including all the colors of the visible light spectrum.\\n2. When sunlight hits the tiny molecules of gases in the atmosphere, such as nitrogen (N2) and oxygen (O2), these molecules scatter the shorter (blue) wavelengths more than the longer (red) wavelengths.\\n3. This is because the smaller molecules are more effective at scattering the shorter wavelengths, which have a higher frequency and energy.\\n4. As a result of this scattering, the blue light is dispersed throughout the atmosphere, giving it a diffuse appearance that makes the sky appear blue to our eyes.\\n\\nIt's worth noting that the color of the sky can also be affected by other factors, such as:\\n\\n* Dust and pollution in the atmosphere, which can scatter light and change its color\\n* The time of day, with the sun's position in the sky affecting the amount of direct sunlight reaching the Earth's surface\\n* Atmospheric conditions like cloud cover or humidity, which can alter the way light is scattered\\n\\nHowever, the basic principle of scattering being responsible for the blue color of the sky remains the same.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "response = chat(model=\"llama3.2\", messages=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Why is the sky blue?\"\n",
    "    }\n",
    "])\n",
    "response[\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structured output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country(name='United States of America', capital='Washington, D.C.', languages=['English', 'Spanish', 'Chinese', 'French', 'Tagalog', 'Vietnamese'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Country(BaseModel):\n",
    "    name: str\n",
    "    capital: str\n",
    "    languages: list[str]\n",
    "    \n",
    "response = chat(\n",
    "    model=\"llama3.2\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me about the US.\"\n",
    "        }\n",
    "    ],\n",
    "    format=Country.model_json_schema()\n",
    ")\n",
    "\n",
    "country = Country.model_validate_json(response.message.content)\n",
    "country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKILL_EXTRACTION_TEMPLATE = \"\"\"\n",
    "You are an expert are parsing skills from resumes.\n",
    "\n",
    "Given resume text, please parse individual technical (e.g., programming languages, tools, frameworks, databases) and domain-specific (e.g., methodologies, architectures, or specialized techniques) skills contained in the resume. **Ensure that you do not miss any domain-specific skills.**\n",
    "\n",
    "Format your output as a JSON object as follows:\n",
    "    {{\n",
    "        \"Technical Skills\": [\"list\", \"of\", \"technical\", \"skills\"]\n",
    "        \"Domain-Specific Skills\": [\"list\", \"of\" \"domain\", \"specific\", \"skills\"]\n",
    "    }}\n",
    "\n",
    "Resume text:\n",
    "```\n",
    "{resume_text}\n",
    "```\n",
    "\n",
    "Parsed skills:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skills(BaseModel):\n",
    "    technical_skills: list[str] = Field(..., alias=\"Technical Skills\")\n",
    "    domain_specific_skills: list[str] = Field(..., alias=\"Domain-Specific Skills\")\n",
    "\n",
    "response = chat(\n",
    "    model=\"llama3.1\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": SKILL_EXTRACTION_TEMPLATE.format(resume_text=resumes[1])\n",
    "        }\n",
    "    ],\n",
    "    options={\"temperature\": 0},\n",
    "    format=Skills.model_json_schema()\n",
    ")\n",
    "\n",
    "skills = Skills.model_validate_json(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Jane Smith\\n'\n",
      " 'Data Scientist\\n'\n",
      " 'jane.smith@example.com | (987) 654-3210 | github.com/janesmith\\n'\n",
      " '\\n'\n",
      " 'Summary:\\n'\n",
      " 'Data scientist with a strong background in machine learning, statistical '\n",
      " 'modeling, and data visualization. Skilled in Python, R, and SQL with '\n",
      " 'experience in predictive analytics.\\n'\n",
      " '\\n'\n",
      " 'Skills:\\n'\n",
      " '- Machine Learning: Scikit-learn, TensorFlow, PyTorch\\n'\n",
      " '- Data Visualization: Tableau, Matplotlib, Seaborn\\n'\n",
      " '- Databases: MySQL, PostgreSQL\\n'\n",
      " '- Tools: Jupyter, Excel, Git\\n'\n",
      " '\\n'\n",
      " 'Experience:\\n'\n",
      " 'Data Scientist | DataCorp | March 2018 - Present\\n'\n",
      " '- Developed machine learning models to predict customer churn, improving '\n",
      " 'retention by 20%.\\n'\n",
      " '- Automated ETL pipelines to streamline data processing, saving 15 hours of '\n",
      " 'manual work weekly.\\n'\n",
      " '\\n'\n",
      " 'Education:\\n'\n",
      " 'M.S. in Data Science | University of ABC | December 2017')\n"
     ]
    }
   ],
   "source": [
    "pprint(resumes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'domain_specific_skills': ['Machine Learning',\n",
      "                            'Predictive Analytics',\n",
      "                            'Statistical Modeling',\n",
      "                            'Data Visualization',\n",
      "                            'ETL Pipelines',\n",
      "                            'Automated Data Processing'],\n",
      " 'technical_skills': ['Python',\n",
      "                      'R',\n",
      "                      'SQL',\n",
      "                      'Scikit-learn',\n",
      "                      'TensorFlow',\n",
      "                      'PyTorch',\n",
      "                      'Tableau',\n",
      "                      'Matplotlib',\n",
      "                      'Seaborn',\n",
      "                      'MySQL',\n",
      "                      'PostgreSQL',\n",
      "                      'Jupyter',\n",
      "                      'Excel',\n",
      "                      'Git']}\n"
     ]
    }
   ],
   "source": [
    "pprint(skills.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
