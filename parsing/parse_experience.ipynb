{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from pydantic import BaseModel, RootModel, Field\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "from utils.with_structured_output import with_structured_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/resume_sections.json\", \"r\") as file:\n",
    "    resume_sections = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experience(BaseModel):\n",
    "    company: str = Field(..., alias=\"Company\")\n",
    "    role: str = Field(..., alias=\"Role\")\n",
    "    contributions: list[str] = Field(..., alias=\"Contributions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIENCE_EXTRACTION_PROMPT = \"\"\"\n",
    "You are an expert at parsing resumes. Given some resume text, your job is to extract information about the candidate's work experience and format it as a list of JSON objects, where each object has the following format:\n",
    "    {{\n",
    "        \"Company\": \"<company>\",\n",
    "        \"Role\": \"<applicant's role at the company>\",\n",
    "        \"Contributions\": [\"list\", \"of\", \"contributions\", \"in\", \"the\", \"role\"]\n",
    "    }}\n",
    "    \n",
    "The extracted information must be **explicitly contained in the resume.**\n",
    "\n",
    "Resume text:\n",
    "{resume_text}\n",
    "\n",
    "Output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'company': 'Sandia National Laboratories',\n",
      "  'contributions': ['Developed knowledge graph (KG) generation pipeline with '\n",
      "                    'internal LLM microservices to allow multi-hop reasoning '\n",
      "                    'in 3-stage retrieval augmented generation (RAG) pipeline',\n",
      "                    'Extracted 30+ domain-specific seed topics from text '\n",
      "                    'corpus with BERTopic for KG subgraph creation',\n",
      "                    'Achieved100%schema-compliantLLMoutputsviaprompt '\n",
      "                    'engineering andgrammar-contrained decoding',\n",
      "                    'Packaged KG generation logic into reusable, '\n",
      "                    'object-oriented Python modules used by 30 developers'],\n",
      "  'role': 'AI/ML Intern'},\n",
      " {'company': 'Sandia National Laboratories',\n",
      "  'contributions': ['Redesigned 30 year old Java data analysis suite '\n",
      "                    'architecture, cutting developer onboarding time by 3 '\n",
      "                    'weeks',\n",
      "                    'Used MATLAB profiler to find bottleneck in data '\n",
      "                    'preprocessing script, leading to 90% execution time '\n",
      "                    'reduction',\n",
      "                    'Built Java class to interface with Javalin REST API, '\n",
      "                    'enabling multithreaded network communication',\n",
      "                    'Reduced logic errors by 50% via integration and '\n",
      "                    'regression testing in Jenkins CI/CD pipeline'],\n",
      "  'role': 'Software Engineering Intern'},\n",
      " {'company': 'Texas A&M University',\n",
      "  'contributions': ['Leading data structures & algorithms recitations for 60 '\n",
      "                    'students semiweekly',\n",
      "                    'Mentoring 15+ students weekly in C++ assignments, leading '\n",
      "                    'to 80% reduction in assignment errors',\n",
      "                    'Teaching students core CS concepts including vectors, '\n",
      "                    'trees, graphs, sorting algorithms, and recursion'],\n",
      "  'role': 'Undergraduate Teaching Assistant'},\n",
      " {'company': 'Vertical Automation and Information Technology',\n",
      "  'contributions': ['Built CRM system with ASP.NET MVC serving 10 users, '\n",
      "                    'improving employee efficiency by 50%',\n",
      "                    'Optimized MySQL database performance by eliminating 1,000 '\n",
      "                    'duplicate records, improving query speed by 10%',\n",
      "                    'Designed scalable SQL database architecture to support '\n",
      "                    'complex entity relationships',\n",
      "                    'Created role-based authorization system with Entity '\n",
      "                    'Framework to facilitate project management for managers'],\n",
      "  'role': 'Full Stack Developer Intern'}]\n"
     ]
    }
   ],
   "source": [
    "experience = with_structured_output(\n",
    "    EXPERIENCE_EXTRACTION_PROMPT.format(resume_text=resume_sections[\"Experience\"]),\n",
    "    RootModel[list[Experience]])\n",
    "pprint(experience.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
